{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6552be3a-afa7-4b47-98ca-9d7e3676542a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/19 16:25:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/19 16:25:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PlayStoreML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b1281f0-ad55-4cde-b22b-2b5272f850ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+----+-----+------+-------------+--------+--------------+\n",
      "|gender |age|                 app|type|price|rating|        genre|installs|content_rating|\n",
      "+-------+---+--------------------+----+-----+------+-------------+--------+--------------+\n",
      "| Female| 17|Photo Editor & Ca...|Free|    0|   4.1| Art & Design|   10000|           4.0|\n",
      "|   Male| 29| Coloring book moana|Free|    0|   3.9|Art & Design |  500000|           4.0|\n",
      "| Female| 69|U Launcher Lite –...|Free|    0|   4.7| Art & Design| 5000000|           4.0|\n",
      "| Female| 19|Sketch - Draw & P...|Free|    0|   4.5| Art & Design|50000000|          12.0|\n",
      "|   Male| 28|Pixel Draw - Numb...|Free|    0|   4.3|Art & Design |  100000|           4.0|\n",
      "+-------+---+--------------------+----+-----+------+-------------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from DBFS or specify the path to the file\n",
    "file_path = \"/Users/anujabavkar/Downloads/Play Store Data.csv\"\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show first few rows of data to understand structure\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd85cde7-85d3-4f84-b11b-c8cf96a60c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['gender ', 'age', 'app', 'type', 'price', 'rating', 'genre', 'installs', 'content_rating']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+----+-----+------+-------------+--------+--------------+---------+------------------+\n",
      "|gender |age|                 app|type|Price|Rating|        genre|Installs|content_rating|TypeIndex|ContentRatingIndex|\n",
      "+-------+---+--------------------+----+-----+------+-------------+--------+--------------+---------+------------------+\n",
      "| Female| 17|Photo Editor & Ca...|Free|  0.0|   4.1| Art & Design|   10000|           4.0|      0.0|               0.0|\n",
      "|   Male| 29| Coloring book moana|Free|  0.0|   3.9|Art & Design |  500000|           4.0|      0.0|               0.0|\n",
      "| Female| 69|U Launcher Lite –...|Free|  0.0|   4.7| Art & Design| 5000000|           4.0|      0.0|               0.0|\n",
      "| Female| 19|Sketch - Draw & P...|Free|  0.0|   4.5| Art & Design|50000000|          12.0|      0.0|               1.0|\n",
      "|   Male| 28|Pixel Draw - Numb...|Free|  0.0|   4.3|Art & Design |  100000|           4.0|      0.0|               0.0|\n",
      "+-------+---+--------------------+----+-----+------+-------------+--------+--------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Inspect column names\n",
    "print(\"Columns:\", data.columns)\n",
    "\n",
    "# Encode categorical columns\n",
    "if \"type\" in data.columns and \"TypeIndex\" not in data.columns:\n",
    "    indexer = StringIndexer(inputCol=\"type\", outputCol=\"TypeIndex\")\n",
    "    data = indexer.fit(data).transform(data)\n",
    "\n",
    "if \"content_rating\" in data.columns and \"ContentRatingIndex\" not in data.columns:\n",
    "    indexer = StringIndexer(inputCol=\"content_rating\", outputCol=\"ContentRatingIndex\")\n",
    "    data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Convert numerical columns to appropriate formats if necessary\n",
    "if \"installs\" in data.columns:\n",
    "    data = data.withColumn(\"Installs\", col(\"installs\").cast(\"int\"))\n",
    "if \"rating\" in data.columns:\n",
    "    data = data.withColumn(\"Rating\", col(\"rating\").cast(\"float\"))\n",
    "if \"price\" in data.columns:\n",
    "    data = data.withColumn(\"Price\", col(\"price\").cast(\"float\"))\n",
    "\n",
    "# Show the first few rows of the transformed data\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "087a82ca-ebb9-4b69-89e1-fd5ed8c30aad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Check and encode categorical columns\n",
    "if \"TypeIndex\" not in data.columns:\n",
    "    indexer = StringIndexer(inputCol=\"Type\", outputCol=\"TypeIndex\")\n",
    "    data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Convert necessary columns to numeric types\n",
    "data = data.withColumn(\"Rating\", col(\"Rating\").cast(\"double\"))\n",
    "data = data.withColumn(\"Installs\", col(\"Installs\").cast(\"double\"))\n",
    "data = data.withColumn(\"Price\", col(\"Price\").cast(\"double\"))\n",
    "\n",
    "# Drop rows with null values in essential columns\n",
    "data = data.dropna(subset=[\"Rating\", \"Installs\", \"TypeIndex\", \"Price\"])\n",
    "\n",
    "# Assemble features for regression model\n",
    "if 'features' in data.columns:\n",
    "    data = data.drop('features')\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Rating\", \"Installs\", \"TypeIndex\"], outputCol=\"features\")\n",
    "data = assembler.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43c514c2-5b8a-4207-98e9-52d4a0c5d990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/19 16:29:31 WARN Instrumentation: [77520b07] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/11/19 16:29:32 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/11/19 16:29:32 WARN Instrumentation: [77520b07] Mean and standard deviation of the label are zero, so the coefficients and the intercept will all be zero; as a result, training is not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|Price|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[3.90000009536743...|  0.0|       0.0|\n",
      "|[3.79999995231628...|  0.0|       0.0|\n",
      "|[4.30000019073486...|  0.0|       0.0|\n",
      "|[4.40000009536743...|  0.0|       0.0|\n",
      "|[4.40000009536743...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) for Linear Regression: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Linear Regression Model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Price\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "predictions = lr_model.transform(test_data)\n",
    "predictions.select(\"features\", \"Price\", \"prediction\").show(5)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) for Linear Regression: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bb8d04e-bf09-4f11-85ae-f0ac3a498e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/19 16:29:40 WARN Instrumentation: [a096b468] All labels are the same value and fitIntercept=true, so the coefficients will be zeros. Training is not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+\n",
      "|            features|TypeIndex|prediction|\n",
      "+--------------------+---------+----------+\n",
      "|[3.90000009536743...|      0.0|       0.0|\n",
      "|[3.79999995231628...|      0.0|       0.0|\n",
      "|[4.30000019073486...|      0.0|       0.0|\n",
      "|[4.40000009536743...|      0.0|       0.0|\n",
      "|[4.40000009536743...|      0.0|       0.0|\n",
      "+--------------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy for Logistic Regression Classification: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Check if 'features' column exists and remove it if it does\n",
    "if 'features' in data.columns:\n",
    "    data = data.drop('features')\n",
    "\n",
    "# Assemble features for logistic regression to predict 'TypeIndex'\n",
    "assembler = VectorAssembler(inputCols=[\"Rating\", \"Installs\", \"Price\"], outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "lr_class = LogisticRegression(featuresCol=\"features\", labelCol=\"TypeIndex\")\n",
    "lr_class_model = lr_class.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_class = lr_class_model.transform(test_data)\n",
    "predictions_class.select(\"features\", \"TypeIndex\", \"prediction\").show(5)\n",
    "\n",
    "# Evaluate the model accuracy\n",
    "evaluator_class = MulticlassClassificationEvaluator(labelCol=\"TypeIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_class.evaluate(predictions_class)\n",
    "print(f\"Accuracy for Logistic Regression Classification: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab91d5ff-3795-4440-99a1-0db7422a89d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|[4.09999990463256...|         0|\n",
      "|[3.90000009536743...|         0|\n",
      "|[4.69999980926513...|         0|\n",
      "|     [4.5,5.0E7,0.0]|         0|\n",
      "|[4.30000019073486...|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Cluster Centers:\n",
      "[3.81317392e+00 9.96537614e+06 0.00000000e+00]\n",
      "[4.26491233e+00 1.00000000e+09 0.00000000e+00]\n",
      "[4.34507048e+00 5.00000000e+08 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Check if 'features' column exists and remove it if it does\n",
    "if 'features' in data.columns:\n",
    "    data = data.drop('features')\n",
    "\n",
    "# Assemble features for KMeans clustering\n",
    "assembler = VectorAssembler(inputCols=[\"Rating\", \"Installs\", \"Price\"], outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Train KMeans Model with 3 clusters\n",
    "kmeans = KMeans(featuresCol=\"features\", k=3)\n",
    "model = kmeans.fit(data)\n",
    "\n",
    "# Make predictions and show clusters\n",
    "predictions_cluster = model.transform(data)\n",
    "predictions_cluster.select(\"features\", \"prediction\").show(5)\n",
    "\n",
    "# Display cluster centers\n",
    "print(\"Cluster Centers:\")\n",
    "for center in model.clusterCenters():\n",
    "  print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4fca13b-292c-49e5-852e-94521205244c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jhjh"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "PlayStore_ML_PySpark_Notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
